{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b84e11-4e6b-40f6-807b-ec27281659e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Nanodet Tutorial\n",
    "\n",
    "This notebook provides a tutorial for running inference on a static image in order to detect objects.\n",
    "The implementation of the [NanodetLearner](../../../../docs/reference/nanodet.md) is largely copied from the [Nanodet github](https://github.com/RangiLyu/nanodet).\n",
    "More information on modifications and license can be found\n",
    "[here](https://github.com/opendr-eu/opendr/blob/master/src/opendr/perception/object_detection_2d/nanodet/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b671ddd9-583b-418a-870e-69dd3c3db718",
   "metadata": {},
   "source": [
    "First, we need to import the learner and initialize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f3d99a-b702-472b-b8d0-95a551e7b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendr.perception.object_detection_2d import NanodetLearner\n",
    "\n",
    "model=\"m\"\n",
    "\n",
    "nanodet = NanodetLearner(model_to_use=model, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5ce70-8294-446a-8cc2-b3eba5e1037b",
   "metadata": {},
   "source": [
    "Note that we can alter the device (e.g., 'cpu', 'cuda', etc.), on which the model runs, as well as the model from a variety of options included a custom you can make (\"EfficientNet_Lite0_320\", \"EfficientNet_Lite1_416\", \"EfficientNet_Lite2_512\",\n",
    "                \"RepVGG_A0_416\", \"t\", \"g\", \"m\", \"m_416\", \"m_0.5x\", \"m_1.5x\", \"m_1.5x_416\",\n",
    "                \"plus_m_320\", \"plus_m_1.5x_320\", \"plus_m_416\", \"plus_m_1.5x_416\", \"custom\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c74615-61ec-43ed-a1ae-57dceedfe938",
   "metadata": {},
   "source": [
    "After creating our model, we need to download pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a680c28-8f42-4b4a-8c6e-2580b7be2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./predefined_examples\"\n",
    "nanodet.download(path=save_path, mode=\"pretrained\")\n",
    "\n",
    "load_model_weights=\"./predefined_examples/nanodet_{}\".format(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e63e7a9-4310-4633-a2ac-052e94ad3ea0",
   "metadata": {},
   "source": [
    "and load our weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f582b-c001-4b9d-b396-4260e23139f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nanodet.load(path=load_model_weights, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ce347-391f-45a1-baf8-91d8a9ce04a7",
   "metadata": {},
   "source": [
    "We will also download one sample image and load it, so we can use it in OpenDR for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efba6eb-5235-4e31-a002-1bcb6e311704",
   "metadata": {},
   "outputs": [],
   "source": [
    "nanodet.download(path=save_path, mode=\"images\")\n",
    "\n",
    "from opendr.engine.data import Image\n",
    "image_path = \"./predefined_examples/000000000036.jpg\"\n",
    "img = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f083566-3d57-4db6-baa5-0fefdf8fa8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(cv2.cvtColor(img.opencv(), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec8ed0d-8e6a-4997-b67d-a5e49f87c0b5",
   "metadata": {},
   "source": [
    "We are now ready to use our model!\n",
    "The only thing that we have to do is to pass the image through the model.\n",
    "Note that there are standard data types supported by OpenDR.\n",
    "However, OpenDR also understands common data types (e.g,. OpenCV images) and automatically converts them into the most\n",
    "appropriate format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab7dae-8892-4a16-ad03-651fa3bb20ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = nanodet.infer(input=img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c85496-89fa-44f8-ad03-a234f466ea4e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can plot the results using a utility function from the Object-Detection-2D module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7129fe6-a198-4196-b35f-93ba41e50031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendr.perception.object_detection_2d import draw_bounding_boxes\n",
    "\n",
    "img_annotated = draw_bounding_boxes(img.opencv(), boxes, class_names=nanodet.classes, show=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_annotated, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436aaefe-fe18-49d7-b881-d0f64ce47742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
